{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3b9fe908-9932-4a9c-892d-6f546020bb05",
      "metadata": {
        "id": "3b9fe908-9932-4a9c-892d-6f546020bb05"
      },
      "source": [
        "# Assignment 4 - Neural Networks and Deep Learning\n",
        "\n",
        "## Deadline: Thursday, November 7 at 11:59 PM\n",
        "## The assignment must be submitted in the form of a Jupyter notebook and uploaded to eClass.\n",
        "\n",
        "## Marks:\n",
        "- Classification task: 5 marks\n",
        "- Regression task: 5 marks\n",
        "\n",
        "**Total: 10 marks**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment, we will revisit datasets we are already familiar with. We will implement multilayer neural networks to perform a classification and a regression task.\n",
        "\n",
        "**Notes:** Some required imports are provided; you will need additional imports. Please make sure no errors occur when you run the notebook sequentially (e.g., `Runtime` $\\to$ `Run all`)."
      ],
      "metadata": {
        "id": "uBLaE-vtEDDf"
      },
      "id": "uBLaE-vtEDDf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification\n",
        "\n",
        "In the first part of the assignment we will revisit the binary classification problem from Assignment 2. You will use the [Parkinson Disease Detection](https://www.kaggle.com/datasets/jainaru/parkinson-disease-detection/data) dataset from kaggle to discriminate healthy people from those with Parkinson's Disease using features extracted from voice recordings.\n",
        "\n"
      ],
      "metadata": {
        "id": "cpWAPloozfwf"
      },
      "id": "cpWAPloozfwf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Marks:\n",
        "- Preprocessing: Load the data, explore the dataset, and create a feature matrix and a target array. Create training and test sets and scale the data.\n",
        "- Step 1. Convert the datasets and target vectors to Pytorch tensors. 0.5 marks.\n",
        "- Step 2. Implement a neural network with at least one hidden layer and train it on the training set. Evaluate the performance of the model on the training set using at least accuracy, sensitivity (a.k.a. recall on class = 1) and specificity (a.k.a. recall for class 0). 1.5 mark.\n",
        "- Step 3. Evaluate the performance of the model on the test set using at least accuracy, sensitivity (a.k.a. recall on class = 1) and specificity (a.k.a. recall for class 0). 1 mark.\n",
        "\n",
        "You may repeat Steps 2 and 3 for different architectures and observe how the performance changes.\n",
        "- Step 4. Does the network overfit the data? Discuss briefly (200 words max). 1 mark.\n",
        "- Step 5. Compare the performance of the neural network with the best classifier from Assignment 2 and discuss briefly (200 words max). 1 mark.\n",
        "\n",
        "**Total = 5 marks.**"
      ],
      "metadata": {
        "id": "x1Fpjtcg2lcc"
      },
      "id": "x1Fpjtcg2lcc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Context"
      ],
      "metadata": {
        "id": "eha_vo5f0yh_"
      },
      "id": "eha_vo5f0yh_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Parkinson's Disease (PD) is a degenerative neurological disorder marked by decreased dopamine levels in the brain. It manifests itself through a deterioration of movement, including the presence of tremors and stiffness. There is commonly a marked effect on speech, including dysarthria (difficulty articulating sounds), hypophonia (lowered volume), and monotone (reduced pitch range). Additionally, cognitive impairments and changes in mood can occur, and risk of dementia is increased.\n",
        "\n",
        "Traditional diagnosis of Parkinson’s Disease involves a clinician taking a neurological history of the patient and observing motor skills in various situations. Since there is no definitive laboratory test to diagnose PD, diagnosis is often difficult, particularly in the early stages when motor effects are not yet severe. Monitoring progression of the disease over time requires repeated clinic visits by the patient. An effective screening process, particularly one that doesn’t require a clinic visit, would be beneficial. Since PD patients exhibit characteristic vocal features, voice recordings are a useful and non-invasive tool for diagnosis. If machine learning algorithms could be applied to a voice recording dataset to accurately diagnosis PD, this would be an effective screening step prior to an appointment with a clinician.\n",
        "\n"
      ],
      "metadata": {
        "id": "460eMcuH0u_E"
      },
      "id": "460eMcuH0u_E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "ehUs52yl0z0Q"
      },
      "id": "ehUs52yl0z0Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds to one of 195 voice recordings from these individuals (\"name\" column). The main aim of the data is to discriminate healthy people from those with PD, according to the \"status\" column which is set to 0 for healthy and 1 for PD."
      ],
      "metadata": {
        "id": "2QRs5aeY0wpl"
      },
      "id": "2QRs5aeY0wpl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "aZ1f-val3Hk0"
      },
      "id": "aZ1f-val3Hk0"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cacde479-b54c-4c3d-bcf9-34047d22762e",
      "metadata": {
        "id": "cacde479-b54c-4c3d-bcf9-34047d22762e"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "665e9314-9ffe-44a1-b946-6fdce5fd5339",
      "metadata": {
        "id": "665e9314-9ffe-44a1-b946-6fdce5fd5339"
      },
      "source": [
        "### Data dictionary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- name - ASCII subject name and recording number\n",
        "- MDVP:Fo(Hz) - Average vocal fundamental frequency\n",
        "- MDVP:Fhi(Hz) - Maximum vocal fundamental frequency\n",
        "- MDVP:Flo(Hz) - Minimum vocal fundamental frequency\n",
        "- MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several\n",
        "measures of variation in fundamental frequency\n",
        "- MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\n",
        "- NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n",
        "- **status** - Health status of the subject (one) - Parkinson's, (zero) - healthy\n",
        "- RPDE,D2 - Two nonlinear dynamical complexity measures\n",
        "- DFA - Signal fractal scaling exponent\n",
        "- spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation'"
      ],
      "metadata": {
        "id": "v3kFJVOT3yt3"
      },
      "id": "v3kFJVOT3yt3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing: Load the data, explore the dataset, and create a feature matrix and a target array. Create training and test sets and scale the data."
      ],
      "metadata": {
        "id": "TIt75VQ03tM1"
      },
      "id": "TIt75VQ03tM1"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8fe53478-9a0f-49b9-bf47-fdce378f5304",
      "metadata": {
        "id": "8fe53478-9a0f-49b9-bf47-fdce378f5304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "4bb15e27-ea53-4101-d0f3-68ae404f8a1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
              "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
              "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
              "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
              "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
              "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
              "\n",
              "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
              "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
              "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
              "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
              "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
              "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
              "\n",
              "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
              "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
              "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
              "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
              "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
              "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
              "\n",
              "    spread2        D2       PPE  \n",
              "0  0.266482  2.301442  0.284654  \n",
              "1  0.335590  2.486855  0.368674  \n",
              "2  0.311173  2.342259  0.332634  \n",
              "3  0.334147  2.405554  0.368975  \n",
              "4  0.234513  2.332180  0.410335  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-469e92fe-524f-470b-8927-3bc7be28c100\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>MDVP:Fo(Hz)</th>\n",
              "      <th>MDVP:Fhi(Hz)</th>\n",
              "      <th>MDVP:Flo(Hz)</th>\n",
              "      <th>MDVP:Jitter(%)</th>\n",
              "      <th>MDVP:Jitter(Abs)</th>\n",
              "      <th>MDVP:RAP</th>\n",
              "      <th>MDVP:PPQ</th>\n",
              "      <th>Jitter:DDP</th>\n",
              "      <th>MDVP:Shimmer</th>\n",
              "      <th>...</th>\n",
              "      <th>Shimmer:DDA</th>\n",
              "      <th>NHR</th>\n",
              "      <th>HNR</th>\n",
              "      <th>status</th>\n",
              "      <th>RPDE</th>\n",
              "      <th>DFA</th>\n",
              "      <th>spread1</th>\n",
              "      <th>spread2</th>\n",
              "      <th>D2</th>\n",
              "      <th>PPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>phon_R01_S01_1</td>\n",
              "      <td>119.992</td>\n",
              "      <td>157.302</td>\n",
              "      <td>74.997</td>\n",
              "      <td>0.00784</td>\n",
              "      <td>0.00007</td>\n",
              "      <td>0.00370</td>\n",
              "      <td>0.00554</td>\n",
              "      <td>0.01109</td>\n",
              "      <td>0.04374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.06545</td>\n",
              "      <td>0.02211</td>\n",
              "      <td>21.033</td>\n",
              "      <td>1</td>\n",
              "      <td>0.414783</td>\n",
              "      <td>0.815285</td>\n",
              "      <td>-4.813031</td>\n",
              "      <td>0.266482</td>\n",
              "      <td>2.301442</td>\n",
              "      <td>0.284654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>phon_R01_S01_2</td>\n",
              "      <td>122.400</td>\n",
              "      <td>148.650</td>\n",
              "      <td>113.819</td>\n",
              "      <td>0.00968</td>\n",
              "      <td>0.00008</td>\n",
              "      <td>0.00465</td>\n",
              "      <td>0.00696</td>\n",
              "      <td>0.01394</td>\n",
              "      <td>0.06134</td>\n",
              "      <td>...</td>\n",
              "      <td>0.09403</td>\n",
              "      <td>0.01929</td>\n",
              "      <td>19.085</td>\n",
              "      <td>1</td>\n",
              "      <td>0.458359</td>\n",
              "      <td>0.819521</td>\n",
              "      <td>-4.075192</td>\n",
              "      <td>0.335590</td>\n",
              "      <td>2.486855</td>\n",
              "      <td>0.368674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>phon_R01_S01_3</td>\n",
              "      <td>116.682</td>\n",
              "      <td>131.111</td>\n",
              "      <td>111.555</td>\n",
              "      <td>0.01050</td>\n",
              "      <td>0.00009</td>\n",
              "      <td>0.00544</td>\n",
              "      <td>0.00781</td>\n",
              "      <td>0.01633</td>\n",
              "      <td>0.05233</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08270</td>\n",
              "      <td>0.01309</td>\n",
              "      <td>20.651</td>\n",
              "      <td>1</td>\n",
              "      <td>0.429895</td>\n",
              "      <td>0.825288</td>\n",
              "      <td>-4.443179</td>\n",
              "      <td>0.311173</td>\n",
              "      <td>2.342259</td>\n",
              "      <td>0.332634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>phon_R01_S01_4</td>\n",
              "      <td>116.676</td>\n",
              "      <td>137.871</td>\n",
              "      <td>111.366</td>\n",
              "      <td>0.00997</td>\n",
              "      <td>0.00009</td>\n",
              "      <td>0.00502</td>\n",
              "      <td>0.00698</td>\n",
              "      <td>0.01505</td>\n",
              "      <td>0.05492</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08771</td>\n",
              "      <td>0.01353</td>\n",
              "      <td>20.644</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434969</td>\n",
              "      <td>0.819235</td>\n",
              "      <td>-4.117501</td>\n",
              "      <td>0.334147</td>\n",
              "      <td>2.405554</td>\n",
              "      <td>0.368975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>phon_R01_S01_5</td>\n",
              "      <td>116.014</td>\n",
              "      <td>141.781</td>\n",
              "      <td>110.655</td>\n",
              "      <td>0.01284</td>\n",
              "      <td>0.00011</td>\n",
              "      <td>0.00655</td>\n",
              "      <td>0.00908</td>\n",
              "      <td>0.01966</td>\n",
              "      <td>0.06425</td>\n",
              "      <td>...</td>\n",
              "      <td>0.10470</td>\n",
              "      <td>0.01767</td>\n",
              "      <td>19.649</td>\n",
              "      <td>1</td>\n",
              "      <td>0.417356</td>\n",
              "      <td>0.823484</td>\n",
              "      <td>-3.747787</td>\n",
              "      <td>0.234513</td>\n",
              "      <td>2.332180</td>\n",
              "      <td>0.410335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-469e92fe-524f-470b-8927-3bc7be28c100')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-469e92fe-524f-470b-8927-3bc7be28c100 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-469e92fe-524f-470b-8927-3bc7be28c100');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4d6aafd8-3bf9-423f-8e60-bdec81d49b43\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d6aafd8-3bf9-423f-8e60-bdec81d49b43')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4d6aafd8-3bf9-423f-8e60-bdec81d49b43 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('PD-1.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the dataset:\n",
        "# Check for missing values and impute missing values if you find any\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "HCmzEAy45CNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64d9a37-1562-4b01-f3a3-59f3eccfbc57"
      },
      "id": "HCmzEAy45CNo",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values:\n",
            "name                0\n",
            "MDVP:Fo(Hz)         0\n",
            "MDVP:Fhi(Hz)        0\n",
            "MDVP:Flo(Hz)        0\n",
            "MDVP:Jitter(%)      0\n",
            "MDVP:Jitter(Abs)    0\n",
            "MDVP:RAP            0\n",
            "MDVP:PPQ            0\n",
            "Jitter:DDP          0\n",
            "MDVP:Shimmer        0\n",
            "MDVP:Shimmer(dB)    0\n",
            "Shimmer:APQ3        0\n",
            "Shimmer:APQ5        0\n",
            "MDVP:APQ            0\n",
            "Shimmer:DDA         0\n",
            "NHR                 0\n",
            "HNR                 0\n",
            "status              0\n",
            "RPDE                0\n",
            "DFA                 0\n",
            "spread1             0\n",
            "spread2             0\n",
            "D2                  0\n",
            "PPE                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The 'name' is not necessary - exclude it from the dataframe\n",
        "df_clean = df.drop('name', axis=1)\n",
        "print(\"Shape after removing 'name':\", df_clean.shape)\n",
        "print(df_clean.head())"
      ],
      "metadata": {
        "id": "UebTqYZEKUGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5835d324-b808-410e-dd8f-39e319623f90"
      },
      "id": "UebTqYZEKUGg",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after removing 'name': (195, 23)\n",
            "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
            "0      119.992       157.302        74.997         0.00784           0.00007   \n",
            "1      122.400       148.650       113.819         0.00968           0.00008   \n",
            "2      116.682       131.111       111.555         0.01050           0.00009   \n",
            "3      116.676       137.871       111.366         0.00997           0.00009   \n",
            "4      116.014       141.781       110.655         0.01284           0.00011   \n",
            "\n",
            "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
            "0   0.00370   0.00554     0.01109       0.04374             0.426  ...   \n",
            "1   0.00465   0.00696     0.01394       0.06134             0.626  ...   \n",
            "2   0.00544   0.00781     0.01633       0.05233             0.482  ...   \n",
            "3   0.00502   0.00698     0.01505       0.05492             0.517  ...   \n",
            "4   0.00655   0.00908     0.01966       0.06425             0.584  ...   \n",
            "\n",
            "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
            "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
            "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
            "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
            "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
            "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
            "\n",
            "    spread2        D2       PPE  \n",
            "0  0.266482  2.301442  0.284654  \n",
            "1  0.335590  2.486855  0.368674  \n",
            "2  0.311173  2.342259  0.332634  \n",
            "3  0.334147  2.405554  0.368975  \n",
            "4  0.234513  2.332180  0.410335  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature matrix and target array\n",
        "X = df_clean.drop('status', axis=1)\n",
        "y = df_clean['status']"
      ],
      "metadata": {
        "id": "8T9DSO595EaE"
      },
      "id": "8T9DSO595EaE",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e26ce919-6e72-4836-a1fd-cf589387be3a",
      "metadata": {
        "id": "e26ce919-6e72-4836-a1fd-cf589387be3a"
      },
      "outputs": [],
      "source": [
        "# Create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "lApxsrNDIHKB"
      },
      "id": "lApxsrNDIHKB",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1. Convert the datasets and target vectors to Pytorch tensors. 0.5 marks."
      ],
      "metadata": {
        "id": "gQRzuGMd6FzK"
      },
      "id": "gQRzuGMd6FzK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Pytorch tensors\n",
        "# Make sure to reshape the target vectors so their shape is (n_samples, 1) and to cast every tensor to float\n",
        "import torch\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "Mh6JPz6l6I8c"
      },
      "id": "Mh6JPz6l6I8c",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8d700c3b-2d8a-4312-9784-fdc6c301d5bc",
      "metadata": {
        "id": "8d700c3b-2d8a-4312-9784-fdc6c301d5bc"
      },
      "source": [
        "### Step 2. Implement a neural network with at least one hidden layer and train it on the training set. Evaluate the performance of the model on the training set using at least accuracy, sensitivity (a.k.a. recall on class = 1) and specificity (a.k.a. recall for class 0). 1.5 mark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4e4ba858-0ed9-451d-9c10-25d245a761a5",
      "metadata": {
        "id": "4e4ba858-0ed9-451d-9c10-25d245a761a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba59c8d-bc88-48c0-fef6-a3f8420f00c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/150], Loss: 0.5769\n",
            "Epoch [30/150], Loss: 0.4864\n",
            "Epoch [45/150], Loss: 0.4127\n",
            "Epoch [60/150], Loss: 0.3492\n",
            "Epoch [75/150], Loss: 0.2949\n",
            "Epoch [90/150], Loss: 0.2680\n",
            "Epoch [105/150], Loss: 0.2168\n",
            "Epoch [120/150], Loss: 0.2063\n",
            "Epoch [135/150], Loss: 0.1661\n",
            "Epoch [150/150], Loss: 0.1507\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ======================\n",
        "# Neural Network (Classification Version)\n",
        "# ======================\n",
        "class ClassificationNetwork(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ClassificationNetwork, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.bn3 = nn.BatchNorm1d(32)\n",
        "\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(self.relu(self.bn1(self.fc1(x))))\n",
        "        x = self.dropout(self.relu(self.bn2(self.fc2(x))))\n",
        "        x = self.dropout(self.relu(self.bn3(self.fc3(x))))\n",
        "        x = self.fc4(x)   # 不加 sigmoid，因為損失函數會自帶\n",
        "        return x\n",
        "\n",
        "\n",
        "# ======================\n",
        "# Build model, loss, optimizer\n",
        "# ======================\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "model = ClassificationNetwork(input_dim=input_dim)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()     # ✅ 改成適合二元分類的 loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ======================\n",
        "# Training\n",
        "# ======================\n",
        "num_epochs = 150\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    outputs = model(X_train_tensor)  # 不用 squeeze\n",
        "    loss = criterion(outputs, y_train_tensor)  # 對齊 [N,1]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "# ======================\n",
        "# Evaluate on test set\n",
        "# ======================\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor).squeeze()\n",
        "    y_pred_prob = torch.sigmoid(test_outputs)      # ✅ 將 logits 轉為機率\n",
        "    y_pred = (y_pred_prob > 0.5).float()           # 二元化"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import accumulate\n",
        "# Evaluate the performance on the training set\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_pred_train = model(X_train_tensor)\n",
        "  y_pred_train = (y_pred_train > 0.5).float()\n",
        "\n",
        "cm = confusion_matrix(y_train_tensor, y_pred_train)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "accumulated_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"=== Training Set Performance ===\")\n",
        "print(f'Accuracy: {accumulated_accuracy:.4f}')\n",
        "print(f'Sensitivity: {sensitivity:.4f}')\n",
        "print(f'Specificity: {specificity:.4f}')"
      ],
      "metadata": {
        "id": "RYcMcn1OKAUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c1bdfe-4abd-425f-e5da-7f0d01e5c7f8"
      },
      "id": "RYcMcn1OKAUF",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Training Set Performance ===\n",
            "Accuracy: 0.9872\n",
            "Sensitivity: 0.9826\n",
            "Specificity: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3. Evaluate the performance of the model on the test set using at least accuracy, sensitivity (a.k.a. recall on class = 1) and specificity (a.k.a. recall for class 0). 1 mark."
      ],
      "metadata": {
        "id": "JEz4Dge_7eA2"
      },
      "id": "JEz4Dge_7eA2"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9bb8177b-1644-4155-afb2-04ce0c296ed0",
      "metadata": {
        "id": "9bb8177b-1644-4155-afb2-04ce0c296ed0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320d0c85-eb24-4e68-ca33-f43789e49d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Test Set Performance ===\n",
            "Accuracy: 0.9231\n",
            "Sensitivity: 0.9688\n",
            "Specificity: 0.7143\n"
          ]
        }
      ],
      "source": [
        "# Performance on the test set\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_pred_test = model(X_test_tensor)\n",
        "  y_pred_test = (y_pred_test > 0.5).float()\n",
        "\n",
        "cm = confusion_matrix(y_test_tensor, y_pred_test)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "accumulated_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"=== Test Set Performance ===\")\n",
        "print(f'Accuracy: {accumulated_accuracy:.4f}')\n",
        "print(f'Sensitivity: {sensitivity:.4f}')\n",
        "print(f'Specificity: {specificity:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4. Does the network overfit the data? Discuss briefly (200 words max). 1 mark."
      ],
      "metadata": {
        "id": "_nblxHlL7jHH"
      },
      "id": "_nblxHlL7jHH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The network shows moderate overfitting. Training performance was nearly perfect (accuracy = 0.9936, sensitivity = 0.9913, specificity = 1.0000), but test accuracy dropped to 0.9231 and specificity to 0.7143. This gap indicates that the model learned patterns specific to the training data and does not generalize as well to unseen samples, especially for negative cases. Possible reasons include the model’s relatively high capacity (three hidden layers with 128–32 neurons), limited training data, and class imbalance, which may cause the network to focus more on positive samples. Although dropout and batch normalization were used to reduce overfitting, these regularization methods may not fully compensate for the network’s complexity. Overall, while the model performs strongly, its reduced test specificity suggests it memorized some training details rather than learning fully generalizable representations."
      ],
      "metadata": {
        "id": "bOnEDLTFMsMw"
      },
      "id": "bOnEDLTFMsMw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5. Compare the performance of the neural network with the best classifier from Assignment 2 and discuss briefly (200 words max). 1 mark."
      ],
      "metadata": {
        "id": "z0odToy97syP"
      },
      "id": "z0odToy97syP"
    },
    {
      "cell_type": "markdown",
      "id": "5446143d-ceba-4485-86ba-97a69090f717",
      "metadata": {
        "id": "5446143d-ceba-4485-86ba-97a69090f717"
      },
      "source": [
        "Compared with the Random Forest classifier from Assignment 2, the neural network achieved slightly higher overall performance. The network reached an accuracy of 0.9231 and sensitivity of 0.9688, outperforming the Random Forest (accuracy = 0.90, sensitivity = 0.95). This indicates that the neural network better identified positive samples and captured more complex nonlinear relationships in the data. However, its specificity (0.7143) was slightly lower than the Random Forest’s 0.73, suggesting that it produced more false positives. Despite this, the neural network’s stronger sensitivity and overall accuracy imply better generalization to the main predictive task. The improvement likely stems from the model’s deeper architecture and the use of batch normalization and dropout, which allowed it to learn richer feature representations. The Random Forest, in contrast, relies on ensemble decision trees and may be less flexible in modeling subtle interactions between features. Overall, while both models performed well, the neural network demonstrated marginally better predictive ability and adaptability at the cost of slightly reduced specificity."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression\n",
        "\n",
        "For our regression task, we will revisit the dataset we used to predict the gestational age of preterm babies using brain structure volumes."
      ],
      "metadata": {
        "id": "6p_3vlXA73ua"
      },
      "id": "6p_3vlXA73ua"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Marks:\n",
        "- Preprocessing: Load the data and create a feature matrix and a target array. Create training and test sets and scale the data.\n",
        "- Step 1. Convert the datasets and target vectors to Pytorch tensors. 0.5 marks.\n",
        "- Step 2. Implement multivariate linear regression using a multilayer neural network and train it on the training set. Evaluate the performance of the model on the training set. 1.5 mark.\n",
        "- Step 3. Evaluate the performance of the model on the test set. 1 mark\n",
        "\n",
        "You may repeat Steps 2 and 3 for different architectures and observe how the performance changes.\n",
        "- Step 4. Does the network overfit the data? Discuss briefly (200 words max). 1 mark.\n",
        "- Step 5. Implement and optimize a Kernel Ridge Regression model. Evaluate its performance and compare it with the neural network you implemented in Step 2. Discuss briefly (200 words max). 1 mark.\n",
        "\n",
        "**Total = 5 marks.**\n"
      ],
      "metadata": {
        "id": "BHMpouaxBuc6"
      },
      "id": "BHMpouaxBuc6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "pADUEP9zGTsi"
      },
      "id": "pADUEP9zGTsi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2l_Jc4NpGo_H"
      },
      "id": "2l_Jc4NpGo_H",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing: Load the data and create a feature matrix and a target array. Create training and test sets and scale the data."
      ],
      "metadata": {
        "id": "1_CbfN_2G8FW"
      },
      "id": "1_CbfN_2G8FW"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('GA-brain-volumes-86-features-2.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HSam_x20G-9_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "b6021ddd-28b8-4c35-cfbe-a6270a1a7f5d"
      },
      "id": "HSam_x20G-9_",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   35.714  0.492  0.617  0.366  0.378  0.608  0.642  0.548  0.525  0.842  ...  \\\n",
              "0  37.429  0.497  0.624  0.361  0.389  0.548  0.589  0.572  0.533  0.883  ...   \n",
              "1  36.143  0.532  0.594  0.374  0.423  0.522  0.648  0.738  0.635  0.797  ...   \n",
              "2  36.714  0.596  0.624  0.407  0.398  0.584  0.642  0.579  0.659  0.787  ...   \n",
              "3  42.286  0.648  0.844  0.414  0.468  0.743  0.874  0.967  1.100  0.936  ...   \n",
              "4  40.143  0.789  0.820  0.400  0.407  0.710  0.829  0.821  0.784  0.966  ...   \n",
              "\n",
              "   0.85  0.841  24.571   24.33  15.489  14.542   54.091  5.85  0.264  0.203  \n",
              "0  1.13  0.850  26.060  26.072  15.089  15.399   55.739  6.15  0.286  0.286  \n",
              "1  1.12  1.110  24.534  24.456  15.616  15.685   80.195  5.89  0.386  0.301  \n",
              "2  1.12  0.998  25.100  24.880  14.396  15.068   64.121  6.11  0.310  0.365  \n",
              "3  1.12  0.964  20.447  19.860  13.999  13.905  120.670  6.44  0.465  0.436  \n",
              "4  1.12  1.300  26.017  25.454  14.307  14.702  110.020  6.34  0.328  0.312  \n",
              "\n",
              "[5 rows x 87 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40226aad-3354-4c39-9708-7434554cfca3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>35.714</th>\n",
              "      <th>0.492</th>\n",
              "      <th>0.617</th>\n",
              "      <th>0.366</th>\n",
              "      <th>0.378</th>\n",
              "      <th>0.608</th>\n",
              "      <th>0.642</th>\n",
              "      <th>0.548</th>\n",
              "      <th>0.525</th>\n",
              "      <th>0.842</th>\n",
              "      <th>...</th>\n",
              "      <th>0.85</th>\n",
              "      <th>0.841</th>\n",
              "      <th>24.571</th>\n",
              "      <th>24.33</th>\n",
              "      <th>15.489</th>\n",
              "      <th>14.542</th>\n",
              "      <th>54.091</th>\n",
              "      <th>5.85</th>\n",
              "      <th>0.264</th>\n",
              "      <th>0.203</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37.429</td>\n",
              "      <td>0.497</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.361</td>\n",
              "      <td>0.389</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.589</td>\n",
              "      <td>0.572</td>\n",
              "      <td>0.533</td>\n",
              "      <td>0.883</td>\n",
              "      <td>...</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.850</td>\n",
              "      <td>26.060</td>\n",
              "      <td>26.072</td>\n",
              "      <td>15.089</td>\n",
              "      <td>15.399</td>\n",
              "      <td>55.739</td>\n",
              "      <td>6.15</td>\n",
              "      <td>0.286</td>\n",
              "      <td>0.286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>36.143</td>\n",
              "      <td>0.532</td>\n",
              "      <td>0.594</td>\n",
              "      <td>0.374</td>\n",
              "      <td>0.423</td>\n",
              "      <td>0.522</td>\n",
              "      <td>0.648</td>\n",
              "      <td>0.738</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.797</td>\n",
              "      <td>...</td>\n",
              "      <td>1.12</td>\n",
              "      <td>1.110</td>\n",
              "      <td>24.534</td>\n",
              "      <td>24.456</td>\n",
              "      <td>15.616</td>\n",
              "      <td>15.685</td>\n",
              "      <td>80.195</td>\n",
              "      <td>5.89</td>\n",
              "      <td>0.386</td>\n",
              "      <td>0.301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36.714</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.407</td>\n",
              "      <td>0.398</td>\n",
              "      <td>0.584</td>\n",
              "      <td>0.642</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.659</td>\n",
              "      <td>0.787</td>\n",
              "      <td>...</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.998</td>\n",
              "      <td>25.100</td>\n",
              "      <td>24.880</td>\n",
              "      <td>14.396</td>\n",
              "      <td>15.068</td>\n",
              "      <td>64.121</td>\n",
              "      <td>6.11</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42.286</td>\n",
              "      <td>0.648</td>\n",
              "      <td>0.844</td>\n",
              "      <td>0.414</td>\n",
              "      <td>0.468</td>\n",
              "      <td>0.743</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.967</td>\n",
              "      <td>1.100</td>\n",
              "      <td>0.936</td>\n",
              "      <td>...</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.964</td>\n",
              "      <td>20.447</td>\n",
              "      <td>19.860</td>\n",
              "      <td>13.999</td>\n",
              "      <td>13.905</td>\n",
              "      <td>120.670</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40.143</td>\n",
              "      <td>0.789</td>\n",
              "      <td>0.820</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.407</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.821</td>\n",
              "      <td>0.784</td>\n",
              "      <td>0.966</td>\n",
              "      <td>...</td>\n",
              "      <td>1.12</td>\n",
              "      <td>1.300</td>\n",
              "      <td>26.017</td>\n",
              "      <td>25.454</td>\n",
              "      <td>14.307</td>\n",
              "      <td>14.702</td>\n",
              "      <td>110.020</td>\n",
              "      <td>6.34</td>\n",
              "      <td>0.328</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 87 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40226aad-3354-4c39-9708-7434554cfca3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-40226aad-3354-4c39-9708-7434554cfca3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-40226aad-3354-4c39-9708-7434554cfca3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4ce1d5c5-90dc-40d5-a7d3-67bd5607b51f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ce1d5c5-90dc-40d5-a7d3-67bd5607b51f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4ce1d5c5-90dc-40d5-a7d3-67bd5607b51f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature matrix and target array\n",
        "# GA is stored in the first column\n",
        "y = df.iloc[:, 0]\n",
        "X = df.iloc[:, 1:]"
      ],
      "metadata": {
        "id": "CV_sHgWyHCBA"
      },
      "id": "CV_sHgWyHCBA",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HUFW1fTfKPXj"
      },
      "id": "HUFW1fTfKPXj",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "scaler_y = StandardScaler()\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "WuEJWkohQ_SV"
      },
      "id": "WuEJWkohQ_SV",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1. Convert the datasets and target vectors to Pytorch tensors. 0.5 marks."
      ],
      "metadata": {
        "id": "uBeYjg1zMFc7"
      },
      "id": "uBeYjg1zMFc7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Pytorch tensors\n",
        "# Make sure to reshape the target vectors so their shape is (n_samples, 1) and to cast every tensor to float\n",
        "import torch\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).reshape(-1, 1)\n",
        "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "Bl15qlLGMKyt"
      },
      "id": "Bl15qlLGMKyt",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2. Implement multivariate linear regression using a multilayer neural network and train it on the training set. Evaluate the performance of the model on the training set. 1.5 mark."
      ],
      "metadata": {
        "id": "32XljVTJNPn_"
      },
      "id": "32XljVTJNPn_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a neural network with at least one hidden layer and train it on the training set.\n",
        "# Hint: use the mean squared error loss from Pytorch\n",
        "# Hint: start with a low learning rate for the optimizer (e.g. 0.001)\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Network Architecture\n",
        "class RegressionNetwork(nn.Module):\n",
        "  def __init__(self, input_dim):\n",
        "    super(RegressionNetwork, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim, 64)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "#Build model, loss function, optimizer\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "model = RegressionNetwork(input_dim=input_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the network on the training set\n",
        "num_epochs = 100\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "\n",
        "  #Forward pass\n",
        "  outputs = model(X_train_tensor)\n",
        "  optimizer.zero_grad() #Clear gradient\n",
        "\n",
        "\n",
        "  #Backward pass and optimization\n",
        "  loss = criterion(outputs, y_train_tensor) #Compute loss\n",
        "  loss.backward() #Compute gradient\n",
        "  optimizer.step() #Renew weights\n",
        "\n",
        "  train_losses.append(loss.item())\n",
        "\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(f'\\nFinal Training Loss: {train_losses[-1]:.4f}')\n"
      ],
      "metadata": {
        "id": "E1NZ6PGENQyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1eead8-0cd1-48d2-d7e5-ef1341b6e547"
      },
      "id": "E1NZ6PGENQyO",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.1587\n",
            "Epoch [20/100], Loss: 0.1404\n",
            "Epoch [30/100], Loss: 0.1064\n",
            "Epoch [40/100], Loss: 0.0829\n",
            "Epoch [50/100], Loss: 0.0661\n",
            "Epoch [60/100], Loss: 0.0546\n",
            "Epoch [70/100], Loss: 0.0456\n",
            "Epoch [80/100], Loss: 0.0387\n",
            "Epoch [90/100], Loss: 0.0331\n",
            "Epoch [100/100], Loss: 0.0284\n",
            "\n",
            "Final Training Loss: 0.0284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RMSE and r2 scores on the training set\n",
        "# Hint: use .detach().numpy() to transform y_pred and y from torch tensors to numpy arrays.\n",
        "# This explicitly removes the \"computational graph\" layer that is intrinsic to torch tensors (used for autograd).\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "model.eval() #Evaluation mode\n",
        "with torch.no_grad(): #No gradient\n",
        "  y_pred_train = model(X_train_tensor)\n",
        "\n",
        "y_pred_train_np = y_pred_train.detach().numpy()\n",
        "y_train_np = y_train_tensor.detach().numpy()\n",
        "\n",
        "y_pred_train_original = scaler_y.inverse_transform(y_pred_train_np)\n",
        "y_train_original = scaler_y.inverse_transform(y_train_np)\n",
        "\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train_original, y_pred_train_original))\n",
        "r2_train = r2_score(y_train_original, y_pred_train_original)\n",
        "\n",
        "print(\"=== Training Set Performance ===\")\n",
        "print(f'RMSE: {rmse_train:.4f}')\n",
        "print(f'R2: {r2_train:.4f}')"
      ],
      "metadata": {
        "id": "e8mV10dOSFwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f7c8b53-eaf6-4048-9347-2e3aee7f0477"
      },
      "id": "e8mV10dOSFwA",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Training Set Performance ===\n",
            "RMSE: 0.6661\n",
            "R2: 0.9720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3. Evaluate the performance of the model on the test set. 1 mark"
      ],
      "metadata": {
        "id": "Ip_xdgQMWSKy"
      },
      "id": "Ip_xdgQMWSKy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RMSE and r2 scores on the test set\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "model.eval()  # Evaluation mode\n",
        "with torch.no_grad():  # No gradient\n",
        "    y_pred_test = model(X_test_tensor)\n",
        "\n",
        "# Convert to numpy\n",
        "y_pred_test_np = y_pred_test.detach().numpy()\n",
        "y_test_np = y_test_tensor.detach().numpy()\n",
        "\n",
        "# Transform back to original scale\n",
        "y_pred_test_original = scaler_y.inverse_transform(y_pred_test_np)\n",
        "y_test_original = scaler_y.inverse_transform(y_test_np)\n",
        "\n",
        "# Calculate metrics on original scale\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test_original, y_pred_test_original))\n",
        "r2_test = r2_score(y_test_original, y_pred_test_original)\n",
        "\n",
        "print(\"=== Test Set Performance ===\")\n",
        "print(f'RMSE: {rmse_test:.4f}')\n",
        "print(f'R² Score: {r2_test:.4f}')"
      ],
      "metadata": {
        "id": "vqz3ADzPVI1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a918706-68b5-4e1a-cb83-8785bebc3850"
      },
      "id": "vqz3ADzPVI1X",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Test Set Performance ===\n",
            "RMSE: 1.2678\n",
            "R² Score: 0.8971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4. Does the network overfit the data? Discuss briefly (200 words max). 1 mark."
      ],
      "metadata": {
        "id": "-JaSIq0hVSRi"
      },
      "id": "-JaSIq0hVSRi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The network demonstrates minimal overfitting with strong generalization performance. The training set achieved an R² score of 0.9787 (RMSE: 0.5809 weeks), while the test set achieved R² of 0.9147 (RMSE: 1.1545 weeks), representing only a 6.4% performance gap.\n",
        "Both sets maintain R² scores above 0.91, indicating the model successfully learned generalizable patterns from brain volume features to predict gestational age. The RMSE increase from 0.58 to 1.15 weeks (approximately 4 days difference) is acceptable for medical prediction tasks and reflects normal generalization error rather than severe overfitting.\n",
        "The modest performance gap suggests the network architecture (input→64→32→1) with ReLU activations provides sufficient capacity without excessive complexity. The standardization of both features and targets likely contributed to stable training and prevented gradient-related issues that could lead to overfitting.\n",
        "**"
      ],
      "metadata": {
        "id": "Hmg1mTMZVU0U"
      },
      "id": "Hmg1mTMZVU0U"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5. Implement and optimize a Kernel Ridge Regression model. Evaluate its performance and compare it with the neural network you implemented in Step 2. Discuss briefly (200 words max). 1 mark."
      ],
      "metadata": {
        "id": "76NjFeJ-WrBd"
      },
      "id": "76NjFeJ-WrBd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Kernel Ridge Regression\n",
        "\n",
        "# Imports\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Create model\n",
        "krr = KernelRidge()\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'alpha': [0.01, 0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': [0.001, 0.01, 0.1, 1, None]\n",
        "}\n",
        "\n",
        "# Perform grid search on the training set\n",
        "print(\"Performing Grid Search...\")\n",
        "grid_search = GridSearchCV(\n",
        "    krr,\n",
        "    param_grid,\n",
        "    cv=5,                    # 5-fold cross-validation\n",
        "    scoring='r2'\n",
        ")\n",
        "\n",
        "# Fit on scaled training data (use the scaled versions, not tensors)\n",
        "grid_search.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Remember optimised model\n",
        "best_krr = grid_search.best_estimator_\n",
        "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best CV R² score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Calculate r2 and RMSE on the training and test set\n",
        "#Training and Test Sets Predictions\n",
        "y_pred_train_krr = best_krr.predict(X_train_scaled)\n",
        "y_pred_test_krr = best_krr.predict(X_test_scaled)\n",
        "\n",
        "#Transform back to original scale\n",
        "y_pred_train_krr_original = scaler_y.inverse_transform(y_pred_train_krr.reshape(-1, 1))\n",
        "y_pred_test_krr_original = scaler_y.inverse_transform(y_pred_test_krr.reshape(-1, 1))\n",
        "\n",
        "# Get original scale targets\n",
        "y_train_original = scaler_y.inverse_transform(y_train_scaled.reshape(-1, 1))\n",
        "y_test_original = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1))\n",
        "\n",
        "# Calculate metrics\n",
        "rmse_train_krr = np.sqrt(mean_squared_error(y_train_original, y_pred_train_krr_original))\n",
        "r2_train_krr = r2_score(y_train_original, y_pred_train_krr_original)\n",
        "\n",
        "rmse_test_krr = np.sqrt(mean_squared_error(y_test_original, y_pred_test_krr_original))\n",
        "r2_test_krr = r2_score(y_test_original, y_pred_test_krr_original)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"=== Kernel Ridge Regression Results ===\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nTraining Set:\")\n",
        "print(f\"  RMSE: {rmse_train_krr:.4f}\")\n",
        "print(f\"  R² Score: {r2_train_krr:.4f}\")\n",
        "print(\"\\nTest Set:\")\n",
        "print(f\"  RMSE: {rmse_test_krr:.4f}\")\n",
        "print(f\"  R² Score: {r2_test_krr:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"=== Comparison: Neural Network vs KRR ===\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\n                 Neural Network  |  Kernel Ridge\")\n",
        "print(f\"Train RMSE:      {rmse_train:.4f}          |  {rmse_train_krr:.4f}\")\n",
        "print(f\"Test RMSE:       {rmse_test:.4f}          |  {rmse_test_krr:.4f}\")\n",
        "print(f\"Train R²:        {r2_train:.4f}          |  {r2_train_krr:.4f}\")\n",
        "print(f\"Test R²:         {r2_test:.4f}          |  {r2_test_krr:.4f}\")\n"
      ],
      "metadata": {
        "id": "o2MXlx-RcGlu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d84e55e-0930-4d8d-9b0c-3ad03820a0e8"
      },
      "id": "o2MXlx-RcGlu",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing Grid Search...\n",
            "\n",
            "Best parameters: {'alpha': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
            "Best CV R² score: 0.9501\n",
            "\n",
            "==================================================\n",
            "=== Kernel Ridge Regression Results ===\n",
            "==================================================\n",
            "\n",
            "Training Set:\n",
            "  RMSE: 0.6139\n",
            "  R² Score: 0.9762\n",
            "\n",
            "Test Set:\n",
            "  RMSE: 1.0612\n",
            "  R² Score: 0.9279\n",
            "\n",
            "==================================================\n",
            "=== Comparison: Neural Network vs KRR ===\n",
            "==================================================\n",
            "\n",
            "                 Neural Network  |  Kernel Ridge\n",
            "Train RMSE:      0.6661          |  0.6139\n",
            "Test RMSE:       1.2678          |  1.0612\n",
            "Train R²:        0.9720          |  0.9762\n",
            "Test R²:         0.8971          |  0.9279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Both models demonstrate excellent performance with comparable results. Grid search identified the optimal KRR configuration as polynomial kernel with alpha=0.1 and gamma=0.001, achieving a cross-validation R² of 0.9501.\n",
        "\n",
        "The neural network achieves marginally better training performance (R²: 0.9787, RMSE: 0.5809 weeks) compared to KRR (R²: 0.9762, RMSE: 0.6139 weeks). However, KRR demonstrates superior generalization on the test set with R² of 0.9279 and RMSE of 1.0612 weeks, outperforming the neural network's test R² of 0.9147 and RMSE of 1.1545 weeks.\n",
        "\n",
        "The smaller train-test performance gap in KRR (R² gap: 4.8% vs 6.4% for neural network; RMSE difference: 0.45 vs 0.57 weeks) indicates better resistance to overfitting. KRR's kernel method efficiently captures non-linear relationships without the complexity of deep learning architectures, making it particularly effective for this moderately-sized structured dataset (86 features).\n",
        "**"
      ],
      "metadata": {
        "id": "d7GyBas4cOHU"
      },
      "id": "d7GyBas4cOHU"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eha_vo5f0yh_",
        "ehUs52yl0z0Q"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}